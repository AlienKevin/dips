# DIPS: Efficient Multi-Criteria Cantonese Word Segmentation

We present DIPS, a novel approach to Cantonese word segmentation that addresses the challenges of balancing model size, inference speed, and accuracy while accommodating diverse segmentation standards. Our method combines fine-tuning, knowledge distillation, structured pruning, and quantization to create a compact and efficient model. DIPS introduces a new segmentation scheme that captures nuanced word boundaries, allowing for flexible multi-criteria segmentation.
Experimental results show that DIPS achieves comparable performance to ELECTRA Small on standard benchmarks while being 17 times smaller (3 MB) and 3 times faster (0.13 ms/token). Our model retains 98.9% of ELECTRA Base's performance on the UD Yue dataset with an F1 score of 0.9560. DIPS offers a practical solution for Cantonese NLP tasks, particularly in resource-constrained environments and real-time applications. The model is available as open-source software, with implementations for Python and JavaScript. Source code and links to pretrained models are available at: https://github.com/AlienKevin/dips.

See my blog for details: https://kevinx.li/projects/dips
